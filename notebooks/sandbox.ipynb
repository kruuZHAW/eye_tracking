{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "# Import Datasets\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_001 = '../data/Project1 Data export_001.tsv'\n",
    "path_002 = '../data/Project1 Data export_002.tsv'\n",
    "path_003 = '../data/Project1 Data export_003.tsv'\n",
    "path_004 = '../data/Project1 Data export_004.tsv'\n",
    "path_005 = '../data/Project1 Data export_005.tsv'\n",
    "path_list = [path_001, path_002, path_003, path_004, path_005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tsv file and return the dataframe\n",
    "def read_tsv(path):\n",
    "    file = pd.read_csv(path,sep='\\t')\n",
    "    file_date = pd.to_datetime(file['Recording timestamp'], unit='s').dt.strftime('%H:%M:%S.%f').str[:-3]\n",
    "    return file, file_date\n",
    "\n",
    "# Get the task range start and end index\n",
    "def task_range_finder(db, task_str):\n",
    "    all_task = db.loc[db['Event'].str.contains('Task', na=False)][\"Recording timestamp\"].to_list()\n",
    "    # Find timestamps where the specified task starts\n",
    "    task_range_start = db.loc[db['Event'] == task_str, 'Recording timestamp'].to_list()\n",
    "    # Compute task end times based on subsequent task start times\n",
    "    task_range_end = [all_task[j+1] #- (5*1e6)  # 5 seconds before the next task\n",
    "                        for j in range(len(all_task) - 1)  \n",
    "                        if all_task[j] in task_range_start]\n",
    "    # Handle case where the last task has no following task\n",
    "    if len(task_range_start) > len(task_range_end):\n",
    "        task_range_end.append(all_task[-1] + (60*1e6))  # 60 seconds after the begining of the last task to be sure to encompass the whole task\n",
    "    return task_range_start, task_range_end\n",
    "\n",
    "\n",
    "# Min-Max transform\n",
    "def min_max_safe_transform(arr):\n",
    "    if arr.shape[0] == 0:\n",
    "        # Return empty 1D array if no samples\n",
    "        return np.array([])\n",
    "    # Fit a new scaler for each array\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(arr)  # shape => (rows, 1)\n",
    "    return scaled.ravel() \n",
    "\n",
    "# Get the gaze point and mouse position data\n",
    "def GP_array_list(db, task_start, task_end):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    all_mouse_x = []\n",
    "    all_mouse_y = []\n",
    "\n",
    "    for i in range(len(task_start)):\n",
    "        x = db['Gaze point X'].iloc[task_start[i]:task_end[i]].dropna().to_numpy().reshape(-1,1)\n",
    "        y = db['Gaze point Y'].iloc[task_start[i]:task_end[i]].dropna().to_numpy().reshape(-1,1)\n",
    "        mouse_x = db['Mouse position X'].iloc[task_start[i]:task_end[i]].dropna().to_numpy().reshape(-1,1)\n",
    "        mouse_y = db['Mouse position Y'].iloc[task_start[i]:task_end[i]].dropna().to_numpy().reshape(-1,1)\n",
    "        #print(x)\n",
    "        # Normalize each array (skip if empty)\n",
    "        x_scaled = min_max_safe_transform(x)\n",
    "        y_scaled = min_max_safe_transform(y)\n",
    "        mouse_x_scaled = min_max_safe_transform(mouse_x)\n",
    "        mouse_y_scaled = min_max_safe_transform(mouse_y)\n",
    "\n",
    "        # Append each result to the lists\n",
    "        all_x.append(x_scaled)\n",
    "        all_y.append(y_scaled)\n",
    "        all_mouse_x.append(mouse_x_scaled)\n",
    "        all_mouse_y.append(mouse_y_scaled)\n",
    "\n",
    "    # Return lists of arrays\n",
    "    return all_x, all_y, all_mouse_x, all_mouse_y\n",
    "\n",
    "\n",
    "def pad_or_truncate_nan(ts, target_length):\n",
    "    \"\"\"\n",
    "    Pads (or truncates) a 1D time-series array 'ts' with NaN \n",
    "    to make it exactly 'target_length' long.\n",
    "    \"\"\"\n",
    "    # Create an array of NaNs\n",
    "    padded = np.full(shape=(target_length,), fill_value=-1)\n",
    "    length = min(len(ts), target_length)\n",
    "    padded[:length] = ts[:length]  # copy up to target_length\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kruu\\AppData\\Local\\Temp\\ipykernel_24788\\3663150026.py:3: DtypeWarning: Columns (76) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  file = pd.read_csv(path,sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "all_files = []\n",
    "for i in range(len(path_list)):\n",
    "    file,_ = read_tsv(path_list[i])\n",
    "    all_files.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Recording timestamp', 'Computer timestamp', 'Sensor', 'Project name',\n",
       "       'Export date', 'Participant name', 'Recording name', 'Recording date',\n",
       "       'Recording date UTC', 'Recording start time',\n",
       "       'Recording start time UTC', 'Recording duration', 'Timeline name',\n",
       "       'Recording Fixation filter name', 'Recording software version',\n",
       "       'Recording resolution height', 'Recording resolution width',\n",
       "       'Recording monitor latency', 'Average calibration accuracy (mm)',\n",
       "       'Average calibration precision SD (mm)',\n",
       "       'Average calibration precision RMS (mm)',\n",
       "       'Average calibration accuracy (degrees)',\n",
       "       'Average calibration precision SD (degrees)',\n",
       "       'Average calibration precision RMS (degrees)',\n",
       "       'Average calibration accuracy (pixels)',\n",
       "       'Average calibration precision SD (pixels)',\n",
       "       'Average calibration precision RMS (pixels)',\n",
       "       'Average validation accuracy (mm)',\n",
       "       'Average validation precision SD (mm)',\n",
       "       'Average validation precision RMS (mm)',\n",
       "       'Average validation accuracy (degrees)',\n",
       "       'Average validation precision SD (degrees)',\n",
       "       'Average validation precision RMS (degrees)',\n",
       "       'Average validation accuracy (pixels)',\n",
       "       'Average validation precision SD (pixels)',\n",
       "       'Average validation precision RMS (pixels)', 'Eyetracker timestamp',\n",
       "       'Event', 'Event value', 'Gaze point X', 'Gaze point Y',\n",
       "       'Gaze point left X', 'Gaze point left Y', 'Gaze point right X',\n",
       "       'Gaze point right Y', 'Gaze direction left X', 'Gaze direction left Y',\n",
       "       'Gaze direction left Z', 'Gaze direction right X',\n",
       "       'Gaze direction right Y', 'Gaze direction right Z',\n",
       "       'Pupil diameter left', 'Pupil diameter right',\n",
       "       'Pupil diameter filtered', 'Eye openness left', 'Eye openness right',\n",
       "       'Eye openness filtered', 'Validity left', 'Validity right',\n",
       "       'Eye position left X (DACSmm)', 'Eye position left Y (DACSmm)',\n",
       "       'Eye position left Z (DACSmm)', 'Eye position right X (DACSmm)',\n",
       "       'Eye position right Y (DACSmm)', 'Eye position right Z (DACSmm)',\n",
       "       'Gaze point left X (DACSmm)', 'Gaze point left Y (DACSmm)',\n",
       "       'Gaze point right X (DACSmm)', 'Gaze point right Y (DACSmm)',\n",
       "       'Gaze point X (MCSnorm)', 'Gaze point Y (MCSnorm)',\n",
       "       'Gaze point left X (MCSnorm)', 'Gaze point left Y (MCSnorm)',\n",
       "       'Gaze point right X (MCSnorm)', 'Gaze point right Y (MCSnorm)',\n",
       "       'Presented Stimulus name', 'Presented Media name',\n",
       "       'Presented Media width', 'Presented Media height',\n",
       "       'Presented Media position X (DACSpx)',\n",
       "       'Presented Media position Y (DACSpx)', 'Original Media width',\n",
       "       'Original Media height', 'Eye movement type',\n",
       "       'Eye movement event duration', 'Eye movement type index',\n",
       "       'Fixation point X', 'Fixation point Y', 'Fixation point X (MCSnorm)',\n",
       "       'Fixation point Y (MCSnorm)', 'Ungrouped', 'Mouse position X',\n",
       "       'Mouse position Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of screen recording in min: 18.937161516666666\n",
      "Total duration in min: 20.649416666666667\n"
     ]
    }
   ],
   "source": [
    "# The unit of the timestamp is in microsecond\n",
    "#Duration of the screen recording in minutes\n",
    "print(f\"Duration of screen recording in min: {(all_files[0].query('Event == \"ScreenRecordingEnd\"')['Recording timestamp'].values - all_files[0].query('Event == \"ScreenRecordingStart\"')['Recording timestamp'].values).item()/(1e6 * 60)}\")\n",
    "\n",
    "#Total duration of the recording in minutes (unit of the columns, miliseconds)\n",
    "print(f\"Total duration in min: {all_files[0][\"Recording duration\"].unique().item()/(1000*60)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recording timestamp\n",
       "0.008333    63238\n",
       "0.008334    30950\n",
       "0.008332     9320\n",
       "0.008331     2464\n",
       "0.008335     1573\n",
       "            ...  \n",
       "0.002701        1\n",
       "0.003793        1\n",
       "0.097263        1\n",
       "0.000479        1\n",
       "0.164029        1\n",
       "Name: count, Length: 8369, dtype: int64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The frequency of recording is 120Hz, that's why consecutive timestamps are at least 8.33ms apart\n",
    "(all_files[0][\"Recording timestamp\"].diff()/1e6).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event\n",
       "MouseEvent                       666\n",
       "KeyboardEvent                    508\n",
       "Task 4                             7\n",
       "Task 1                             6\n",
       "Task 3                             6\n",
       "Task 5                             6\n",
       "Task 6                             6\n",
       "Task 2                             6\n",
       "RecordingStart                     1\n",
       "Eye tracker Calibration start      1\n",
       "ScreenRecordingStart               1\n",
       "Eye tracker Calibration end        1\n",
       "ScreenRecordingEnd                 1\n",
       "RecordingEnd                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[0][\"Event\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = task_range_finder(all_files[0], 'Task 6')\n",
    "# (np.array(end) - np.array(start))/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384650848, 506481709, 595375103, 633562973, 761980973, 790936973]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384650848, 425124426, 535555769, 633562973, 664384973, 790936973, 827283973]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why start and end are not the same length?\n",
    "# We have to find out why\n",
    "# Some ends are before the corresponding starts: we have to find out why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
