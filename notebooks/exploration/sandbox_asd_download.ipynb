{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f9e517",
   "metadata": {},
   "source": [
    "****\n",
    "# Helpers for key normalizer\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0ba3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "_CAMEL_RE = re.compile(r'(?<!^)(?=[A-Z])')\n",
    "_SPECIALS = {\n",
    "    \"latDeg\": \"lat_deg\",\n",
    "    \"lonDeg\": \"lon_deg\",\n",
    "    \"trackNumber\": \"track_number\",\n",
    "    \"flightId\": \"flight_id\",\n",
    "    \"latLon\": \"lat_lon\",\n",
    "    \"positionUpdated\": \"position_updated\",\n",
    "    \"measurementId\": \"measurement_id\",\n",
    "    \"transferType\": \"transfer_type\", \n",
    "    \"clearanceType\": \"clearance_type\", \n",
    "    \"flightId1\": \"flight_id1\",\n",
    "    \"flightId2\": \"flight_id2\",\n",
    "    \"modeUpdated\": \"mode_updated\",\n",
    "    \"lengthSeconds\":\"length_seconds\",\n",
    "    \"actionName\": \"action_name\",\n",
    "    \"markType\": \"mark_type\",\n",
    "    \"markVariant\": \"mark_variant\",\n",
    "    \"markScope\": \"mark_scope\",\n",
    "    \"markSet\": \"mark_set\",\n",
    "    \"flightId\": \"flight_id\",\n",
    "    \"trackNumber\": \"track_number\",\n",
    "}\n",
    "\n",
    "def _to_snake(s): \n",
    "    if not isinstance(s,str): return s\n",
    "    return _SPECIALS.get(s, _CAMEL_RE.sub('_', s).lower())\n",
    "\n",
    "def _normalize_keys(obj):\n",
    "    if isinstance(obj, Dict):\n",
    "        return {_to_snake(k): _normalize_keys(v) for k,v in obj.items()}\n",
    "    if isinstance(obj, List):\n",
    "        return [_normalize_keys(x) for x in obj]\n",
    "    return obj\n",
    "\n",
    "def _flatten_mp(prefix, mp, *, log_conflicts=False):\n",
    "    \"\"\"MeasurementPoint for distance measurement-> flat dict under <prefix>_* with backfill from flight_id.track_number.\"\"\"\n",
    "    out = {}\n",
    "    if not isinstance(mp, Dict):\n",
    "        return out\n",
    "\n",
    "    fi = mp.get(\"flight_id\") or {}\n",
    "\n",
    "    # --- track_number with backfill from nested flight_id.track_number ---\n",
    "    tn_top = mp.get(\"track_number\")\n",
    "    tn_fi  = fi.get(\"track_number\")\n",
    "    tn = tn_top if tn_top is not None else tn_fi\n",
    "    out[f\"{prefix}_track_number\"] = tn\n",
    "\n",
    "    if log_conflicts and (tn_top is not None and tn_fi is not None and tn_top != tn_fi):\n",
    "        out[f\"{prefix}_track_number_conflict\"] = True  # boolean flag\n",
    "\n",
    "    # --- kind + lat/lon or flight_id expansion ---\n",
    "    if isinstance(mp.get(\"lat_lon\"), Dict):\n",
    "        out[f\"{prefix}_kind\"] = \"lat_lon\"\n",
    "        out[f\"{prefix}_lat_deg\"] = mp[\"lat_lon\"].get(\"lat_deg\")\n",
    "        out[f\"{prefix}_lon_deg\"] = mp[\"lat_lon\"].get(\"lon_deg\")\n",
    "    elif isinstance(fi, Dict) and len(fi):\n",
    "        out[f\"{prefix}_kind\"] = \"flight_id\"\n",
    "        for k, v in fi.items():\n",
    "            out[f\"{prefix}_flight_{k}\"] = v\n",
    "    else:\n",
    "        out[f\"{prefix}_kind\"] = \"unknown\"\n",
    "\n",
    "    return out\n",
    "\n",
    "def _get(d, *names):\n",
    "    \"\"\"Safe getter that tries multiple key spellings (snake & camel).\"\"\"\n",
    "    if not isinstance(d, Dict):\n",
    "        return None\n",
    "    for k in names:\n",
    "        if k in d:\n",
    "            return d[k]\n",
    "    return None\n",
    "\n",
    "_COORD_RE = re.compile(r\"^(\\d{2})(\\d{2})([NS])(\\d{3})(\\d{2})([EW])$\")  # e.g. 5700N01305E, 5624N01341E\n",
    "\n",
    "def _norm_action_name(s):\n",
    "    return None if not isinstance(s, str) else s.strip().upper().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "\n",
    "def _parse_compact_coord(s):\n",
    "    \"\"\"\n",
    "    Parse strings like '5700N01305E' into (lat_deg, lon_deg).\n",
    "    Returns (lat, lon) as floats or (None, None) if not matching.\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return None, None\n",
    "    m = _COORD_RE.match(s.strip())\n",
    "    if not m:\n",
    "        return None, None\n",
    "    lat_deg = int(m.group(1))\n",
    "    lat_min = int(m.group(2))\n",
    "    lat_hem = m.group(3)\n",
    "    lon_deg = int(m.group(4))\n",
    "    lon_min = int(m.group(5))\n",
    "    lon_hem = m.group(6)\n",
    "\n",
    "    lat = lat_deg + lat_min / 60.0\n",
    "    lon = lon_deg + lon_min / 60.0\n",
    "    if lat_hem == \"S\": lat = -lat\n",
    "    if lon_hem == \"W\": lon = -lon\n",
    "    return lat, lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6693c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_mouse_position(asd_dict):\n",
    "    prefix = \"mouse_position\"\n",
    "    if \"mouse_position\" not in asd_dict: return None\n",
    "    p = asd_dict[\"mouse_position\"]\n",
    "    return {\"event_name\":\"mouse_position\",f\"{prefix}_x\":p.get(\"x\"),f\"{prefix}_y\":p.get(\"y\")}\n",
    "\n",
    "def rows_track_screen_position(asd_dict):\n",
    "    prefix = \"track_screen_position\"\n",
    "    if \"track_screen_position\" not in asd_dict: return None\n",
    "    p = asd_dict[\"track_screen_position\"]\n",
    "    return {\"event_name\":\"track_screen_position\",f\"{prefix}_x\":p.get(\"x\"),f\"{prefix}_y\":p.get(\"y\"),\n",
    "            f\"{prefix}_track_number\":p.get(\"track_number\"),\n",
    "            f\"{prefix}_visible\":p.get(\"visible\"), **{f\"{prefix}_flight_{k}\":v for k,v in (p.get(\"flight_id\") or {}).items()}}\n",
    "\n",
    "def rows_track_label_position(asd_dict):\n",
    "    prefix = \"track_label_position\"\n",
    "    if \"track_label_position\" not in asd_dict: return None\n",
    "    p = asd_dict[\"track_label_position\"]\n",
    "    out = {\"event_name\":\"track_label_position\",f\"{prefix}_x\":p.get(\"x\"),f\"{prefix}_y\":p.get(\"y\"),\n",
    "           f\"{prefix}_width\":p.get(\"width\"),f\"{prefix}_height\":p.get(\"height\"),\n",
    "           f\"{prefix}_visible\":p.get(\"visible\"),f\"{prefix}_hovered\":p.get(\"hovered\"),\n",
    "           f\"{prefix}_selected\":p.get(\"selected\"),f\"{prefix}_on_pip\":p.get(\"on_pip\"),\n",
    "           f\"{prefix}_track_number\":p.get(\"track_number\"),\n",
    "           **{f\"{prefix}_flight_{k}\":v for k,v in (p.get(\"flight_id\") or {}).items()}}\n",
    "    return out\n",
    "\n",
    "def rows_speed_vector(asd_dict):\n",
    "    prefix = \"speed_vector\"\n",
    "    sv = asd_dict.get(\"speed_vector\")\n",
    "    if not isinstance(sv, Dict): return None\n",
    "    # oneof update -> one of: mode_updated, visibility, length\n",
    "    if \"mode_updated\" in sv:\n",
    "        return {\"event_name\":\"speed_vector\", f\"{prefix}_variant\":\"mode_updated\",\n",
    "                f\"{prefix}_mode_name\": sv[\"mode_updated\"].get(\"mode\")}\n",
    "    if \"visibility\" in sv:\n",
    "        v = sv[\"visibility\"]\n",
    "        tn = v.get(\"track_number\") or (v.get(\"flight_id\") or {}).get(\"track_number\")\n",
    "        vis = v.get(\"visible\")\n",
    "        return {\"event_name\":\"speed_vector\",f\"{prefix}_variant\":\"visibility\",f\"{prefix}_track_number\":tn,\n",
    "                f\"{prefix}_visible\":vis,\n",
    "                f\"{prefix}_visibility_event_type\": (\"set_true\" if vis is True else \"set_false\" if vis is False else \"touched\"),\n",
    "                **{f\"{prefix}_flight_{k}\":v for k,v in (v.get(\"flight_id\") or {}).items()}}\n",
    "    if \"length\" in sv:\n",
    "        return {\"event_name\":\"speed_vector\",f\"{prefix}_variant\":\"length\",\n",
    "                f\"{prefix}_length_seconds\": sv[\"length\"].get(\"length_seconds\")}\n",
    "    return None\n",
    "\n",
    "def rows_popup(asd_dict):\n",
    "    prefix = \"popup\"\n",
    "    p = asd_dict.get(\"popup\")\n",
    "    if not isinstance(p, Dict): return None\n",
    "    tn = p.get(\"track_number\") or (p.get(\"flight_id\") or {}).get(\"track_number\")\n",
    "    base = {\"event_name\":\"popup\",f\"{prefix}_name\":p.get(\"name\"),f\"{prefix}_opened\":p.get(\"opened\"),\n",
    "            f\"{prefix}_track_number\":tn}\n",
    "    base.update({f\"{prefix}_flight_{k}\":v for k,v in (p.get(\"flight_id\") or {}).items()})\n",
    "    return base\n",
    "\n",
    "def rows_transfer(asd_dict):\n",
    "    prefix = \"transfer\"\n",
    "    t = asd_dict.get(\"transfer\")\n",
    "    if not isinstance(t, Dict): return None\n",
    "    tn = t.get(\"track_number\") or (t.get(\"flight_id\") or {}).get(\"track_number\")\n",
    "    base = {\"event_name\":\"transfer\",\"transfer_type_name\":t.get(\"transfer_type\"),\n",
    "            f\"{prefix}_track_number\":tn}\n",
    "    base.update({f\"{prefix}_flight_{k}\":v for k,v in (t.get(\"flight_id\") or {}).items()})\n",
    "    return base\n",
    "\n",
    "def rows_clearance(asd_dict):\n",
    "    prefix = \"clearance\"\n",
    "    c = asd_dict.get(\"clearance\")\n",
    "    if not isinstance(c, Dict): return None\n",
    "    tn = c.get(\"track_number\") or (c.get(\"flight_id\") or {}).get(\"track_number\")\n",
    "    base = {\"event_name\":\"clearance\",\"clearance_type\":c.get(\"clearance_type\"),\n",
    "            \"clearance\": c.get(\"clearance\"), f\"{prefix}_track_number\": tn}\n",
    "    base.update({f\"{prefix}_flight_{k}\":v for k,v in (c.get(\"flight_id\") or {}).items()})\n",
    "    return base\n",
    "\n",
    "def rows_distance_measurement(asd_dict):\n",
    "    \"\"\"\n",
    "    Return a flat dict for one DistanceMeasurement event or None.\n",
    "    Expected columns (aligns with SCHEMA_DISTANCE columns_out):\n",
    "      change, measurement_id,\n",
    "      first_track_number, first_kind, first_lat_deg, first_lon_deg,\n",
    "      second_track_number, second_kind, second_lat_deg, second_lon_deg,\n",
    "      start_x, start_y, end_x, end_y\n",
    "    \"\"\"\n",
    "    # Top-level: distance_measurement\n",
    "    prefix = \"distance_measurement\"\n",
    "    dm = _get(asd_dict, \"distance_measurement\", \"distanceMeasurement\")\n",
    "    if not isinstance(dm, Dict):\n",
    "        return None\n",
    "\n",
    "    row = {\"event_name\": \"distance_measurement\"}\n",
    "\n",
    "    added = _get(dm, \"added\", \"added\")\n",
    "    if isinstance(added, Dict):\n",
    "        row[f\"{prefix}_change\"] = \"added\"\n",
    "        row[f\"{prefix}_measurement_id\"] = _get(added, \"measurement_id\", \"measurementId\")\n",
    "        # first / second MeasurementPoint (may be by lat_lon or flight_id)\n",
    "        first  = _get(added, \"first\",  \"first\")\n",
    "        second = _get(added, \"second\", \"second\")\n",
    "        if first:\n",
    "            row.update(_flatten_mp(f\"{prefix}_first\", first))\n",
    "        if second:\n",
    "            row.update(_flatten_mp(f\"{prefix}_second\", second))\n",
    "        return row\n",
    "\n",
    "    pos = _get(dm, \"position_updated\", \"positionUpdated\")\n",
    "    if isinstance(pos, Dict):\n",
    "        row[f\"{prefix}_change\"] = \"position_updated\"\n",
    "        row[f\"{prefix}_measurement_id\"] = _get(pos, \"measurement_id\", \"measurementId\")\n",
    "        start = _get(pos, \"start\", \"start\") or {}\n",
    "        end   = _get(pos, \"end\",   \"end\")   or {}\n",
    "        row[f\"{prefix}_start_x\"] = _get(start, \"x\", \"x\")\n",
    "        row[f\"{prefix}_start_y\"] = _get(start, \"y\", \"y\")\n",
    "        row[f\"{prefix}_end_x\"]   = _get(end,   \"x\", \"x\")\n",
    "        row[f\"{prefix}_end_y\"]   = _get(end,   \"y\", \"y\")\n",
    "        return row\n",
    "\n",
    "    removed = _get(dm, \"removed\", \"removed\")\n",
    "    if isinstance(removed, Dict):\n",
    "        row[f\"{prefix}_change\"] = \"removed\"\n",
    "        row[f\"{prefix}_measurement_id\"] = _get(removed, \"measurement_id\", \"measurementId\")\n",
    "        return row\n",
    "\n",
    "    return None\n",
    "    \n",
    "def rows_sep_tool(asd_dict):\n",
    "    \"\"\"\n",
    "    Flatten one Separation Tool event into a single row dict.\n",
    "\n",
    "    Produces:\n",
    "      sep_type, change,\n",
    "      opened_track_number,\n",
    "      connected_track_number_1, connected_track_number_2,\n",
    "      closed,\n",
    "    plus any expanded opened_flight_* / connected_flight1_* / connected_flight2_* fields.\n",
    "    \"\"\"\n",
    "    # top-level key \n",
    "    prefix = \"sep_tool\"\n",
    "    st = _get(asd_dict, \"sep_tool\", \"sepTool\")\n",
    "    if not isinstance(st, Dict):\n",
    "        return None\n",
    "\n",
    "    row = {\"event_name\": \"sep_tool\"}\n",
    "\n",
    "    # common type\n",
    "    row[f\"{prefix}_type\"] = _get(st, \"type\", \"type\")\n",
    "\n",
    "    # variant: opened\n",
    "    opened = _get(st, \"opened\", \"opened\")\n",
    "    if isinstance(opened, Dict):\n",
    "        row[f\"{prefix}_change\"] = \"opened\"\n",
    "        fi = _get(opened, \"flight_id\", \"flightId\") or {}\n",
    "        row[f\"{prefix}_opened_track_number\"] = _get(fi, \"track_number\", \"trackNumber\")\n",
    "        # expand nested flight id\n",
    "        if isinstance(fi, Dict):\n",
    "            for k, v in fi.items():\n",
    "                row[f\"{prefix}_opened_flight_{_to_snake(k)}\"] = v\n",
    "        return row\n",
    "\n",
    "    # variant: connected\n",
    "    connected = _get(st, \"connected\", \"connected\")\n",
    "    if isinstance(connected, Dict):\n",
    "        row[f\"{prefix}_change\"] = \"connected\"\n",
    "        fi1 = _get(connected, \"flight_id1\", \"flightId1\") or {}\n",
    "        fi2 = _get(connected, \"flight_id2\", \"flightId2\") or {}\n",
    "        row[f\"{prefix}_connected_track_number_1\"] = _get(fi1, \"track_number\", \"trackNumber\")\n",
    "        row[f\"{prefix}_connected_track_number_2\"] = _get(fi2, \"track_number\", \"trackNumber\")\n",
    "        # expand nested\n",
    "        if isinstance(fi1, Dict):\n",
    "            for k, v in fi1.items():\n",
    "                row[f\"{prefix}_connected_flight1_{_to_snake(k)}\"] = v\n",
    "        if isinstance(fi2, Dict):\n",
    "            for k, v in fi2.items():\n",
    "                row[f\"{prefix}_connected_flight2_{_to_snake(k)}\"] = v\n",
    "        return row\n",
    "\n",
    "    # variant: closed (boolean or dict)\n",
    "    if \"closed\" in st:\n",
    "        row[f\"{prefix}_change\"] = \"closed\"\n",
    "        row[f\"{prefix}_closed\"] = bool(_get(st, \"closed\", \"closed\"))\n",
    "        return row\n",
    "\n",
    "    # unknown shape\n",
    "    row[f\"{prefix}_change\"] = None\n",
    "    return row\n",
    "\n",
    "def rows_route_interaction(asd_dict):\n",
    "    \"\"\"\n",
    "    Flatten one route_interaction event into a row dict compatible with SCHEMA_ROUTE.\n",
    "    Produces:\n",
    "      event_name='route_interaction',\n",
    "      action_type_raw, action_type_name,\n",
    "      value, value_kind, value_lat_deg, value_lon_deg,\n",
    "      track_number, and any flight_* fields (e.g., flight_uuid, flight_track_number).\n",
    "    \"\"\"\n",
    "    # top-level key\n",
    "    prefix = \"route_interaction\"\n",
    "    ri = _get(asd_dict, \"route_interaction\", \"routeInteraction\")\n",
    "    if not isinstance(ri, dict):\n",
    "        return None\n",
    "\n",
    "    row = {\"event_name\": \"route_interaction\"}\n",
    "\n",
    "    # action type\n",
    "    action_raw = _get(ri, \"action_type\", \"actionType\")\n",
    "    row[f\"{prefix}_action_type_raw\"]  = action_raw\n",
    "    row[f\"{prefix}_action_type_name\"] = _norm_action_name(action_raw)\n",
    "\n",
    "    # value + optional compact coord parse\n",
    "    val = _get(ri, \"value\", \"value\")\n",
    "    row[f\"{prefix}_value\"] = val\n",
    "    lat, lon = _parse_compact_coord(val)\n",
    "    row[f\"{prefix}_value_lat_deg\"] = lat\n",
    "    row[f\"{prefix}_value_lon_deg\"] = lon\n",
    "    row[f\"{prefix}_value_kind\"] = (\"coord\" if lat is not None else (\"fix\" if isinstance(val, str) else None))\n",
    "\n",
    "    # flight_id + backfill track_number\n",
    "    fi = _get(ri, \"flight_id\", \"flightId\") or {}\n",
    "    tn = _get(ri, \"track_number\", \"trackNumber\") or _get(fi, \"track_number\", \"trackNumber\")\n",
    "    row[f\"{prefix}_track_number\"] = tn\n",
    "\n",
    "    # expand flight_id.* -> flight_*\n",
    "    if isinstance(fi, dict):\n",
    "        for k, v in fi.items():\n",
    "            row[f\"{prefix}_flight_{_to_snake(k)}\"] = v\n",
    "\n",
    "    return row\n",
    "\n",
    "def rows_keyboard_shortcut(asd_dict):\n",
    "    \"\"\"\n",
    "    Flatten one KeyboardShortcut event into a row.\n",
    "\n",
    "    Produces:\n",
    "        event_name = 'keyboard_shortcut'\n",
    "        action_name\n",
    "        action_name_norm\n",
    "    (exactly matching SCHEMA_KEYBOARD)\n",
    "    \"\"\"\n",
    "    # Key may be keyboard_shortcut or keyboardShortcut depending on source\n",
    "    prefix = \"keyboard\"\n",
    "    ks = _get(asd_dict, \"keyboard_shortcut\", \"keyboardShortcut\")\n",
    "    if not isinstance(ks, dict):\n",
    "        return None\n",
    "\n",
    "    # Extract action name\n",
    "    name = _get(ks, \"action_name\", \"actionName\")\n",
    "\n",
    "    return {\n",
    "        \"event_name\": \"keyboard_shortcut\",\n",
    "        f\"{prefix}_action_name\": name,\n",
    "        f\"{prefix}_action_name_norm\": _norm_action_name(name),\n",
    "    }\n",
    "\n",
    "def rows_mark(asd_dict):\n",
    "    \"\"\"\n",
    "    Flatten one track_mark / mark event into a row.\n",
    "\n",
    "    Produces fields compatible with SCHEMA_MARK:\n",
    "      mark_type_raw, mark_variant_raw, mark_scope_raw,\n",
    "      mark_type_name, mark_variant_name, mark_scope_name,\n",
    "      mark_set, mark_action,\n",
    "      track_number,\n",
    "      plus any flight_* fields (e.g. flight_track_number, flight_uuid).\n",
    "    \"\"\"\n",
    "    # Top-level message may be named \"track_mark\" or \"trackMark\"\n",
    "    prefix = \"track_mark\"\n",
    "    m = _get(asd_dict, \"track_mark\", \"trackMark\", \"mark\")\n",
    "    if not isinstance(m, dict):\n",
    "        return None\n",
    "\n",
    "    out = {\"event_name\": \"track_mark\"}\n",
    "\n",
    "    # raw values\n",
    "    out[\"mark_type_raw\"]    = _get(m, \"mark_type\", \"markType\")\n",
    "    out[\"mark_variant_raw\"] = _get(m, \"mark_variant\", \"markVariant\")\n",
    "    out[\"mark_scope_raw\"]   = _get(m, \"mark_scope\", \"markScope\")\n",
    "    out[\"mark_set\"]         = _get(m, \"mark_set\", \"markSet\")\n",
    "\n",
    "    # normalized (for grouping)\n",
    "    out[\"mark_type_name\"]    = _norm_action_name(out[\"mark_type_raw\"])\n",
    "    out[\"mark_variant_name\"] = _norm_action_name(out[\"mark_variant_raw\"])\n",
    "    out[\"mark_scope_name\"]   = _norm_action_name(out[\"mark_scope_raw\"])\n",
    "\n",
    "    # derive an action label\n",
    "    if out[\"mark_set\"] is True:\n",
    "        out[\"mark_action\"] = \"SET\"\n",
    "    elif out[\"mark_set\"] is False:\n",
    "        out[\"mark_action\"] = \"UNSET\"\n",
    "    else:\n",
    "        out[\"mark_action\"] = \"TOUCH\"\n",
    "\n",
    "    # track number: top-level, else from flight_id.track_number\n",
    "    tn = _get(m, \"track_number\", \"trackNumber\")\n",
    "    fi = _get(m, \"flight_id\", \"flightId\") or {}\n",
    "    if tn is None and isinstance(fi, dict):\n",
    "        tn = _get(fi, \"track_number\", \"trackNumber\")\n",
    "    out[f\"{prefix}_track_number\"] = tn\n",
    "\n",
    "    # expand flight_id.* â†’ flight_*\n",
    "    if isinstance(fi, dict):\n",
    "        for k, v in fi.items():\n",
    "            out[f\"{prefix}_flight_{_to_snake(k)}\"] = v\n",
    "\n",
    "    return out\n",
    "\n",
    "EXTRACTORS = [\n",
    "    rows_mouse_position,\n",
    "    rows_track_screen_position,\n",
    "    rows_track_label_position,\n",
    "    rows_speed_vector,\n",
    "    rows_popup,\n",
    "    rows_transfer,\n",
    "    rows_clearance,\n",
    "    rows_distance_measurement,\n",
    "    rows_sep_tool,\n",
    "    rows_route_interaction,\n",
    "    rows_keyboard_shortcut,\n",
    "    rows_mark,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada74da",
   "metadata": {},
   "source": [
    "****\n",
    "# Pull raw ASD events as dicts from SQLite\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fba014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from aware_protos.aware.proto import messages_pb2\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "def iter_asd_events(db_path: Path, start_ms: int, end_ms: int, batch=50_000):\n",
    "    \n",
    "    uri = f\"file:{db_path}?mode=ro&immutable=1\"\n",
    "    con = sqlite3.connect(uri, uri=True)\n",
    "    con.text_factory = bytes\n",
    "    con.execute(\"PRAGMA query_only=ON\")\n",
    "    con.execute(\"PRAGMA mmap_size=268435456\")\n",
    "    con.execute(\"PRAGMA temp_store=MEMORY\")\n",
    "\n",
    "    sql = ('SELECT epoch_ms, payload FROM \"events\" '\n",
    "           'WHERE epoch_ms BETWEEN ? AND ? ORDER BY epoch_ms')\n",
    "    cur = con.execute(sql, (start_ms, end_ms))\n",
    "    try:\n",
    "        while True:\n",
    "            rows = cur.fetchmany(batch)\n",
    "            if not rows:\n",
    "                break\n",
    "            for ms, blob in rows:\n",
    "                ev = messages_pb2.Event()\n",
    "                ev.ParseFromString(blob)\n",
    "                if ev.WhichOneof(\"payload\") != \"asd_event\":\n",
    "                    continue\n",
    "                # Convert to dict (camelCase), then normalize to snake_case\n",
    "                d = MessageToDict(ev.asd_event, preserving_proto_field_name=True)\n",
    "                yield int(ms), _normalize_keys(d)\n",
    "    finally:\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbe9dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# from utils.build_raw_inputs import find_scenarios, find_et_tsv, find_sim_db, build_et_frame\n",
    "\n",
    "# root = \"/store/kruu/eye_tracking/training_data\"\n",
    "# scenarios = find_scenarios(Path(root))\n",
    "\n",
    "# i = 0\n",
    "\n",
    "# for _, _, scen_dir in scenarios:\n",
    "#     et = find_et_tsv(scen_dir)\n",
    "#     db = find_sim_db(scen_dir)\n",
    "#     if not et or not db:\n",
    "#         print(f\"[skip] Missing ET or DB in: {scen_dir}\", file=sys.stderr)\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         df_et = build_et_frame(et)\n",
    "#         if df_et.empty:\n",
    "#             print(f\"[warn] ET slice empty in {et}\", file=sys.stderr)\n",
    "#             continue\n",
    "        \n",
    "#         iter_asd = iter_asd_events(db, int(df_et[\"epoch_ms\"].min()), int(df_et[\"epoch_ms\"].max()))\n",
    "#         if i == 10:\n",
    "#             break\n",
    "#         i+=1\n",
    "#     except Exception as e:\n",
    "#         print(f\"[error] {scen_dir}: {e}\", file=sys.stderr)\n",
    "#         continue\n",
    "\n",
    "\n",
    "\n",
    "# count_total = 0\n",
    "# count_dm = 0\n",
    "# examples = []\n",
    "\n",
    "# for ms, asd in iter_asd:\n",
    "#     count_total += 1\n",
    "\n",
    "#     r_dm = rows_keyboard_shortcut(asd)\n",
    "#     if r_dm:\n",
    "#         count_dm += 1\n",
    "#         r_dm[\"epoch_ms\"] = ms\n",
    "#         examples.append(r_dm)\n",
    "#         # Stop early after a few to inspect structure\n",
    "#         if len(examples) < 5:\n",
    "#             print(\"\\n--- Example event ---\")\n",
    "#             print(r_dm)\n",
    "\n",
    "# print(f\"\\nDecoded {count_dm} events of {count_total} total ASD events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3c317e",
   "metadata": {},
   "source": [
    "****\n",
    "# Merging\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zoneinfo import ZoneInfo\n",
    "TZ = ZoneInfo(\"Europe/Zagreb\")\n",
    "\n",
    "def load_selected_asd(db_path: Path, start_ms: int, end_ms: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for ms, asd in iter_asd_events(db_path, start_ms, end_ms):\n",
    "        for f in EXTRACTORS:\n",
    "            r = f(asd)\n",
    "            if r:\n",
    "                r[\"epoch_ms\"] = ms\n",
    "                rows.append(r)\n",
    "    if not rows:\n",
    "        return pd.DataFrame()\n",
    "    df = pd.DataFrame(rows).sort_values(\"epoch_ms\").reset_index(drop=True)\n",
    "    # tidy types for common fields\n",
    "    for c in (\"x\",\"y\",\"width\",\"height\",\"track_number\",\"length_seconds\"):\n",
    "        if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\").astype(\"Int32\")\n",
    "    for c in (\"visible\",\"opened\"):\n",
    "        if c in df.columns: df[c] = df[c].map(lambda v: None if pd.isna(v) else bool(v)).astype(\"boolean\")\n",
    "    return df\n",
    "\n",
    "# Because we are doing some separate feature engineering on ET and Mouse data, we actually don't need to merge them. We only need to have them\n",
    "# in the same time window, and compute the features separately. \n",
    "\n",
    "# def merge_et_mouse_asd(df_et: pd.DataFrame, df_asd: pd.DataFrame, out_parquet: Path, tol_ms=8):\n",
    "#     dfe = df_et.astype({\"epoch_ms\":\"int64\"}).sort_values(\"epoch_ms\")\n",
    "#     # Merging mouse data to the nearest ET observation based on many to one:\n",
    "#     # For each ET observation we take the closest mouse observation within tol_ms\n",
    "#     # One mouse observation might be associated to several ET, and other to none.\n",
    "#     # Other ASD events are saved separately\n",
    "#     dfm = df_asd.astype({\"epoch_ms\":\"int64\"}).query(\"event_name=='mouse_position'\")[[\"epoch_ms\",\"mouse_position_x\",\"mouse_position_y\"]]\n",
    "#     merged = pd.merge_asof(dfe, dfm, on=\"epoch_ms\", direction=\"nearest\", tolerance=tol_ms)\n",
    "\n",
    "#     ts_utc = pd.to_datetime(merged[\"epoch_ms\"], unit=\"ms\", utc=True)\n",
    "#     merged[\"ts_cet\"] = ts_utc.dt.tz_convert(TZ)\n",
    "\n",
    "#     # out_parquet.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     # merged.to_parquet(out_parquet, index=False)\n",
    "#     return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e3cf420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kruu/git_folder/eye_tracking/utils/build_raw_inputs.py:125: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(tsv_path, sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from utils.build_raw_inputs import find_scenarios, find_et_tsv, find_sim_db, build_et_frame\n",
    "\n",
    "root = \"/store/kruu/eye_tracking/training_data\"\n",
    "scenarios = find_scenarios(Path(root))\n",
    "\n",
    "et = find_et_tsv(scenarios[0][2])\n",
    "db = find_sim_db(scenarios[0][2])\n",
    "df_et = build_et_frame(et)\n",
    "\n",
    "df_asd = load_selected_asd(db, int(df_et[\"epoch_ms\"].min()), int(df_et[\"epoch_ms\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb7a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mouse = (\n",
    "#     df_asd.query(\"event_name == 'mouse_position'\")\n",
    "#           .rename(columns={\n",
    "#               \"mouse_position_x\": \"Mouse position X\",\n",
    "#               \"mouse_position_y\": \"Mouse position Y\",\n",
    "#           })\n",
    "#           [[\"epoch_ms\", \"Mouse position X\", \"Mouse position Y\"]]\n",
    "# )\n",
    "# merged = merge_and_write(df_et, df_mouse, out_parquet, tol_ms=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
